{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dnB1f4Ugknn",
        "outputId": "2e295198-f768-478d-b519-d60756dfd611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting musiclm-pytorch\n",
            "  Downloading musiclm_pytorch-0.2.2-py3-none-any.whl (12 kB)\n",
            "Collecting accelerate (from musiclm-pytorch)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting audiolm-pytorch>=0.17.0 (from musiclm-pytorch)\n",
            "  Downloading audiolm_pytorch-1.2.26-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beartype (from musiclm-pytorch)\n",
            "  Downloading beartype-0.15.0-py3-none-any.whl (777 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.6/777.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6 (from musiclm-pytorch)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lion-pytorch (from musiclm-pytorch)\n",
            "  Downloading lion_pytorch-0.1.2-py3-none-any.whl (4.4 kB)\n",
            "Collecting vector-quantize-pytorch>=1.0.0 (from musiclm-pytorch)\n",
            "  Downloading vector_quantize_pytorch-1.6.30-py3-none-any.whl (13 kB)\n",
            "Collecting x-clip (from musiclm-pytorch)\n",
            "  Downloading x_clip-0.12.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.12 in /usr/local/lib/python3.10/dist-packages (from musiclm-pytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from musiclm-pytorch) (2.0.2+cu118)\n",
            "Collecting ema-pytorch>=0.2.2 (from audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading ema_pytorch-0.2.3-py3-none-any.whl (4.4 kB)\n",
            "Collecting encodec (from audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fairseq (from audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.3.1)\n",
            "Collecting local-attention>=1.8.4 (from audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading local_attention-1.8.6-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.2.2)\n",
            "Collecting sentencepiece (from audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->musiclm-pytorch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->musiclm-pytorch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->musiclm-pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->musiclm-pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->musiclm-pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->musiclm-pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12->musiclm-pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12->musiclm-pytorch) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate->musiclm-pytorch) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->musiclm-pytorch) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->musiclm-pytorch) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->musiclm-pytorch) (6.0.1)\n",
            "Collecting ftfy (from x-clip->musiclm-pytorch)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from x-clip->musiclm-pytorch) (2022.10.31)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from x-clip->musiclm-pytorch) (0.15.2+cu118)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.29.36)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitarray (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading bitarray-2.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.8/283.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->x-clip->musiclm-pytorch) (0.2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12->musiclm-pytorch) (2.1.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->audiolm-pytorch>=0.17.0->musiclm-pytorch) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12->musiclm-pytorch) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->x-clip->musiclm-pytorch) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->x-clip->musiclm-pytorch) (9.4.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->audiolm-pytorch>=0.17.0->musiclm-pytorch) (2023.6.0)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (4.9.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->x-clip->musiclm-pytorch) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->x-clip->musiclm-pytorch) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->x-clip->musiclm-pytorch) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->x-clip->musiclm-pytorch) (3.4)\n",
            "Building wheels for collected packages: encodec, fairseq, antlr4-python3-runtime\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=ea15dedeb5f591d7d1a02d64ae1bad4e4ccf48d8b3f6c0056e6140217b2d6027\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11288406 sha256=70c05f61133ff817373a1b96b5807363050c01afaf5f01ae2ad040428dc6141a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=194f396272cfdffaf28383e7a27cd33fbb4c3ac174b5d0b7cade1352409e8bd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built encodec fairseq antlr4-python3-runtime\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, bitarray, antlr4-python3-runtime, portalocker, omegaconf, ftfy, einops, colorama, beartype, sacrebleu, hydra-core, huggingface-hub, transformers, vector-quantize-pytorch, local-attention, lion-pytorch, fairseq, encodec, ema-pytorch, accelerate, x-clip, audiolm-pytorch, musiclm-pytorch\n",
            "Successfully installed accelerate-0.21.0 antlr4-python3-runtime-4.8 audiolm-pytorch-1.2.26 beartype-0.15.0 bitarray-2.8.0 colorama-0.4.6 einops-0.6.1 ema-pytorch-0.2.3 encodec-0.1.1 fairseq-0.12.2 ftfy-6.1.1 huggingface-hub-0.16.4 hydra-core-1.0.7 lion-pytorch-0.1.2 local-attention-1.8.6 musiclm-pytorch-0.2.2 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1 safetensors-0.3.1 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.31.0 vector-quantize-pytorch-1.6.30 x-clip-0.12.2\n"
          ]
        }
      ],
      "source": [
        "!pip install musiclm-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From MusicLM-Pytorch"
      ],
      "metadata": {
        "id": "jvERohSlZ3ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlZxQteZgrQM",
        "outputId": "940c7152-cb30-4a57-c8c8-9f19ae1c6f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from musiclm_pytorch import MuLaN, AudioSpectrogramTransformer, TextTransformer\n",
        "\n",
        "audio_transformer = AudioSpectrogramTransformer(\n",
        "    dim = 512,\n",
        "    depth = 6,\n",
        "    heads = 8,\n",
        "    dim_head = 64,\n",
        "    spec_n_fft = 128,\n",
        "    spec_win_length = 24,\n",
        "    spec_aug_stretch_factor = 0.8\n",
        ")\n",
        "\n",
        "text_transformer = TextTransformer(\n",
        "    dim = 512,\n",
        "    depth = 6,\n",
        "    heads = 8,\n",
        "    dim_head = 64\n",
        ")\n",
        "\n",
        "mulan = MuLaN(\n",
        "    audio_transformer = audio_transformer,\n",
        "    text_transformer = text_transformer\n",
        ")\n",
        "\n",
        "# get a ton of <sound, text> pairs and train\n",
        "\n",
        "wavs = torch.randn(2, 1024)\n",
        "texts = torch.randint(0, 20000, (2, 256))\n",
        "\n",
        "loss = mulan(wavs, texts)\n",
        "loss.backward()\n",
        "\n",
        "embeds = mulan.get_audio_latents(wavs)\n",
        "\n",
        "embeds = mulan.get_text_latents(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VivfvyRCgm-T",
        "outputId": "11c092fb-7b99-469a-9bc0-3950ba2223f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spectrogram yielded shape of (65, 86), but had to be cropped to (64, 80) to be patchified for transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from musiclm_pytorch import MuLaNEmbedQuantizer\n",
        "\n",
        "quantizer = MuLaNEmbedQuantizer(\n",
        "    mulan = mulan,\n",
        "    conditioning_dims = (1024, 1024, 1024),\n",
        "    namespaces = ('semantic', 'coarse', 'fine')\n",
        ")\n",
        "\n",
        "wavs = torch.randn(2, 1024)\n",
        "conds = quantizer(wavs = wavs, namespace = 'semantic') # (2, 8, 1024)"
      ],
      "metadata": {
        "id": "S-L6oiH2gsyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from audiolm_pytorch import HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer\n",
        "\n",
        "wav2vec = HubertWithKmeans(\n",
        "    checkpoint_path = './hubert/hubert_base_ls960.pt',\n",
        "    kmeans_path = './hubert/hubert_base_ls960_L9_km500.bin'\n",
        ")\n",
        "\n",
        "semantic_transformer = SemanticTransformer(\n",
        "    num_semantic_tokens = wav2vec.codebook_size,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    audio_text_condition = True      # this must be set to True (same for CoarseTransformer and FineTransformers)\n",
        ").cuda()\n",
        "\n",
        "trainer = SemanticTransformerTrainer(\n",
        "    transformer = semantic_transformer,\n",
        "    wav2vec = wav2vec,\n",
        "    audio_conditioner = quantizer,\n",
        "    folder ='/content/test.mp3',\n",
        "    batch_size = 1,\n",
        "    data_max_length = 320 * 32,\n",
        "    num_train_steps = 1\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "-wBfhc2ggvly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution"
      ],
      "metadata": {
        "id": "1pTKRev_g1TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from musiclm_pytorch import MusicLM\n",
        "\n",
        "musiclm = MusicLM(\n",
        "    audio_lm = audio_lm,\n",
        "    mulan_embed_quantizer = quantizer\n",
        ")\n",
        "\n",
        "music = musiclm(\"I can't wait for this wonderful experience!\", num_samples = 3)"
      ],
      "metadata": {
        "id": "y2PiJCL3g1gN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}